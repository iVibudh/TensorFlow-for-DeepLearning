{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Try to understand the questions and give critiques to the solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Predict Rain - Bayes' Rule\n",
    "\n",
    "https://www.youtube.com/watch?v=ooqFCXMdxys\n",
    "\n",
    "Predict rain based on cloudy weather or not. \n",
    "1st thing-> Bayes' Rule  <br>\n",
    "P(A/B) = P(B/A) * P(A) / P(B) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Identify Fish - Classification Task\n",
    "\n",
    "https://www.youtube.com/watch?v=bXpONCq5ePE&t=7s\n",
    "\n",
    "Classify fish into -> Salmon, trout, tuna, and cod\n",
    "Input Features -> Fish length, body length, weight, type of scales(round, long or no scales)\n",
    "\n",
    "1. Transform the input features so that we can feed these vaalues into the ML model and predict them.  <br>\n",
    "- Convert the categorical variable to numberic ( transform to dummy variables)  <br>\n",
    "You only need 2 dummy variables to represent the 3 categories of the variable: Round and Long <br>\n",
    "Round -> (1, 0),  <br>\n",
    "Long ->(0, 1),  <br>\n",
    "No Scales -> (0, 0)\n",
    "\n",
    "2. Normalization of the variables. (with the help of standard deviation or variance)  <br>\n",
    "Subtract with the mean and divide with the standard deviation\n",
    "\n",
    "\n",
    "3. Classification Problem\n",
    "Try Random forest, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Detect Plagiarism - tf-idf, Clustering, and NLP\n",
    "\n",
    "https://www.youtube.com/watch?v=B3w_msqHP68\n",
    "\n",
    "Cosine similarity -> tf-idf method to vectorize my documents - then I could find the cosing similayity between all the documents. \n",
    "\n",
    "- tf-idf\n",
    "Will generate frequecy of certain words. So documents that have the same frequency of certain words will have a higher cosine similarity. Each vector is a frquency of certain word. \n",
    "\n",
    "Problem: two essay could have similar counts of the words but could have a different language used. \n",
    "so, maybe look at n-grams (which are series of words that appear multiple times) Look at frequencies of n-grams. It captures the context. \n",
    "\n",
    "NLP - try to look at similar sentence structure. if 1 word is modified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Reduce Data Dimentiality - Image classification \n",
    "\n",
    "https://www.youtube.com/watch?v=NzzpasA9GsM\n",
    "\n",
    "Image (1920, 1080, 3) - Improve the processing time. \n",
    "\n",
    "1. Perform a transformation before feeding into the model. - Fourier Transform <br>\n",
    "This transformation will look for frequencies of diffreent colour patters. This could dramatically reduce the dimentiality of our data <br>\n",
    "After Fourier Transformation, we are looking for the patterns instead of counting every pixel by pixel. So, there is a loss of information that may happen in this transformation. We can chcek how the accuracy is affected.\n",
    "\n",
    "A transformation like Fourier might work really well on Audio and Video. Since the devices to record the data are capturing the walelengths and transferring those to frequencies. <br>\n",
    "Someting that is not in the form of these wavelengths and the frequencies of these wavelengths for those Fourier Transformation might not be a great idea. \n",
    "\n",
    "2. Implement a multi-threaded parallel processing. \n",
    "This can improve the processing time. \n",
    "\n",
    "Feedback: https://www.youtube.com/watch?v=sbB-0qV33uM <br>\n",
    "For Images, the pixel vvalues can be highly corelated and there could be patters that you can exploit, and condense the data. We could have also talked about taking Principal Components (PCA). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Describe your ML Project \n",
    "\n",
    "https://www.youtube.com/watch?v=jjdbGD4CBGk\n",
    "\n",
    "Create your own personal Live Jazz band. \n",
    "- explain the problem statement \n",
    "- explain preprocessing \n",
    "- explain ML models \n",
    "- Explain and compare multiple ML models - SVM and Random Forest\n",
    "\n",
    "Compare SVM\n",
    "https://www.youtube.com/watch?v=r7g0Z-54vg0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Explain how SVM works\n",
    "\n",
    "https://www.youtube.com/watch?v=RyThtU8GcT0\n",
    "\n",
    "Tweak the kernels to have a curved boundry. Or try a different ML model. \n",
    "\n",
    "https://www.youtube.com/watch?v=pMjG1IJRSb8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arpan's Analysis of the interview \n",
    "\n",
    "https://www.youtube.com/watch?v=mnQ2n026Y2o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
