{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GWvKKFRdxvP"
      },
      "source": [
        "# Controlling Agent Reasoning Loop with `return_direct` in Tools\n",
        "\n",
        "\n",
        "In this tutorial, we'll explore how to control the reasoning loop of an agent using the `return_direct` option available in tools.\n",
        "\n",
        "This feature plays a crucial role in streamlining the agent's decision-making process, particularly when immediate output from a single tool is sufficient for the task at hand rather than sending the output of tool to LLM for final response.\n",
        "\n",
        "Setting `return_direct` to True impacts the agent's reasoning loop. When activated and the corresponding tool is called independently, the loop concludes, and the output from the tool is directly returned.\n",
        "\n",
        "By the end of this tutorial, you'll have a comprehensive understanding of how to leverage the `return_direct` option to enhance the efficiency of an agent's reasoning loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8TKwkFYft3y"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w1rb_v0OfIPS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in c:\\users\\vibud\\miniconda3\\lib\\site-packages (0.10.40)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.2.1)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.11)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.40 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.10.40)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.13)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.12)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (2024.3.1)\n",
            "Requirement already satisfied: httpx in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.14.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (2.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (9.5.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.10.15)\n",
            "Requirement already satisfied: anyio in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (4.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.40->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.40->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.40->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.9.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.40->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.40->llama-index) (2.2.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.40->llama-index) (3.0.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.40->llama-index) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.40->llama-index) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.40->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.40->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-index-llms-openai in c:\\users\\vibud\\miniconda3\\lib\\site-packages (0.1.13)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-llms-openai) (0.10.40)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.3.1)\n",
            "Requirement already satisfied: httpx in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.14.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (9.5.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: pydantic>=1.10 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.10.15)\n",
            "Requirement already satisfied: anyio in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: click in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vibud\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dd8MzkGuLhtq"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "from llama_index.core.bridge.pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN6rmRGzfvxp"
      },
      "source": [
        "### Setup LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZsWxupGkLd39"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR OPENAI API KEY'\n",
        "\n",
        "llm = OpenAI(model='gpt-4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fyiLNhCdhSz"
      },
      "source": [
        "Here, we are defining a system to manage restaurant bookings using various functions and integrating them into a tool-based architecture.\n",
        "\n",
        "The `Booking` class is a Pydantic model used to track and represent the state of a booking. It includes optional fields like name, email, phone, date, and time, allowing for flexible data entry.\n",
        "\n",
        "`get_booking_state(user_id: str):` Retrieves the current state of a booking using the booking ID. It outputs the booking's details or a message if the ID is not found.\n",
        "\n",
        "`update_booking(user_id: str, property: str, value: str):` Updates a specific property of a booking. It's designed to modify only the provided details.\n",
        "\n",
        "`create_booking(user_id: str):` Initializes a new booking and stores it under a unique ID, prompting the user to provide further details.\n",
        "\n",
        "`confirm_booking(user_id: str):` Finalizes the booking after ensuring all necessary information is provided. If any detail is missing, it raises an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YAX6Hk2KLR4r"
      },
      "outputs": [],
      "source": [
        "# we will store booking under random IDs\n",
        "bookings = {}\n",
        "\n",
        "class Booking(BaseModel):\n",
        "    name: Optional[str] = None\n",
        "    email: Optional[str] = None\n",
        "    phone: Optional[str] = None\n",
        "    date: Optional[str] = None\n",
        "    time: Optional[str] = None\n",
        "\n",
        "\n",
        "def get_booking_state(user_id: str) -> str:\n",
        "    \"\"\"Get the current state of a booking for a given booking ID.\"\"\"\n",
        "    try:\n",
        "        return str(bookings[user_id].dict())\n",
        "    except:\n",
        "        return f\"Booking ID {user_id} not found\"\n",
        "\n",
        "\n",
        "def update_booking(user_id: str, property: str, value: str) -> str:\n",
        "    \"\"\"Update a property of a booking for a given booking ID. Only enter details that are explicitly provided.\"\"\"\n",
        "    booking = bookings[user_id]\n",
        "    setattr(booking, property, value)\n",
        "    return f\"Booking ID {user_id} updated with {property} = {value}\"\n",
        "\n",
        "\n",
        "def create_booking(user_id: str) -> str:\n",
        "    \"\"\"Create a new booking and return the booking ID.\"\"\"\n",
        "    bookings[user_id] = Booking()\n",
        "    return \"Booking created, but not yet confirmed. Please provide your name, email, phone, date, and time.\"\n",
        "\n",
        "\n",
        "def confirm_booking(user_id: str) -> str:\n",
        "    \"\"\"Confirm a booking for a given booking ID.\"\"\"\n",
        "    booking = bookings[user_id]\n",
        "\n",
        "    if booking.name is None:\n",
        "        raise ValueError(\"Please provide your name.\")\n",
        "\n",
        "    if booking.email is None:\n",
        "        raise ValueError(\"Please provide your email.\")\n",
        "\n",
        "    if booking.phone is None:\n",
        "        raise ValueError(\"Please provide your phone number.\")\n",
        "\n",
        "    if booking.date is None:\n",
        "        raise ValueError(\"Please provide the date of your booking.\")\n",
        "\n",
        "    if booking.time is None:\n",
        "        raise ValueError(\"Please provide the time of your booking.\")\n",
        "\n",
        "    return f\"Booking ID {user_id} confirmed!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-gnfyueAR_"
      },
      "source": [
        "We will demonstrate two experiments:\n",
        "\n",
        "**Experiment-1:** `return_direct` is not enabled in `get_booking_state_tool`\n",
        "\n",
        "**Experiment-2:** `return_direct` is enabled in `get_booking_state_tool`\n",
        "\n",
        "Once the entire booking process is complete and confirmed, we will review the booking details to understand how the final response differs when `return_direct` is enabled versus when it is disabled.\n",
        "\n",
        "In both experiments, we will enable `return_direct` for `create_booking_tool` and `confirm_booking_tool` as we don't need the output to be sent to LLM for the final response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MaNgeNJe_gT"
      },
      "source": [
        "### Experiment-1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA6cotp2fDAC"
      },
      "source": [
        "#### Create Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTSPV9M7ZBJN"
      },
      "outputs": [],
      "source": [
        "get_booking_state_tool = FunctionTool.from_defaults(fn=get_booking_state)\n",
        "update_booking_tool = FunctionTool.from_defaults(fn=update_booking)\n",
        "create_booking_tool = FunctionTool.from_defaults(fn=create_booking,\n",
        "                                                 return_direct=True)\n",
        "confirm_booking_tool = FunctionTool.from_defaults(fn=confirm_booking,\n",
        "                                                  return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RunKZhOZDyI"
      },
      "outputs": [],
      "source": [
        "user = \"user123\"\n",
        "prefix_messages = [\n",
        "    ChatMessage(\n",
        "        role=\"system\",\n",
        "        content=(\n",
        "            f\"You are now connected to the booking system and helping {user} with making a booking. \"\n",
        "            \"Only enter details that the user has explicitly provided. \"\n",
        "            \"Do not make up any details.\"\n",
        "        ),\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dljg64zzfFER"
      },
      "source": [
        "#### Create Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPej4q4fLW0X"
      },
      "outputs": [],
      "source": [
        "worker = FunctionCallingAgentWorker(\n",
        "    tools=[\n",
        "        get_booking_state_tool,\n",
        "        update_booking_tool,\n",
        "        create_booking_tool,\n",
        "        confirm_booking_tool,\n",
        "    ],\n",
        "    llm=llm,\n",
        "    prefix_messages=prefix_messages,\n",
        "    max_function_calls=10,\n",
        "    allow_parallel_tool_calls=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "agent = AgentRunner(worker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJGN2l1DfMMQ"
      },
      "source": [
        "#### Let's create booking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXWBwCuMLZWW",
        "outputId": "ad234cf7-b2f6-4fac-b065-6409115ba466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Hello! I would like to make a booking.\n",
            "=== Calling Function ===\n",
            "Calling function: create_booking with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "Booking created, but not yet confirmed. Please provide your name, email, phone, date, and time.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Hello! I would like to make a booking.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RggA5SdhLkT0",
        "outputId": "fe6528d6-35ac-4b60-9982-34530b6b88ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Sure! My name is Ravi, and my email is ravi@gmail.com\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"name\", \"value\": \"Ravi\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with name = Ravi\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"email\", \"value\": \"ravi@gmail.com\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with email = ravi@gmail.com\n",
            "=== LLM Response ===\n",
            "Thank you, Ravi. Could you please provide your phone number, and the date and time you would like to make the booking for?\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Sure! My name is Ravi, and my email is ravi@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ItQatd0LrI8",
        "outputId": "91dfa9f8-99ba-4c1d-9b76-7779ff035e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Cool. Phone number is 39429384923, preferred data and time are April 20th and 12PM respectively.\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"phone\", \"value\": \"39429384923\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with phone = 39429384923\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"date\", \"value\": \"April 20th\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with date = April 20th\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"time\", \"value\": \"12PM\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with time = 12PM\n",
            "=== Calling Function ===\n",
            "Calling function: confirm_booking with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 confirmed!\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Cool. Phone number is 39429384923, preferred data and time are April 20th and 12PM respectively.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdNVByBqMHZF",
        "outputId": "bf98083d-da21-4062-8833-1bd635cb58fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: provide booking details of user user123\n",
            "=== Calling Function ===\n",
            "Calling function: get_booking_state with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "{'name': 'Ravi', 'email': 'ravi@gmail.com', 'phone': '39429384923', 'date': 'April 20th', 'time': '12PM'}\n",
            "=== LLM Response ===\n",
            "Here are the booking details for user123:\n",
            "\n",
            "- Name: Ravi\n",
            "- Email: ravi@gmail.com\n",
            "- Phone: 39429384923\n",
            "- Date: April 20th\n",
            "- Time: 12PM\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"provide booking details of user user123\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhSfavCswzrh",
        "outputId": "edc4bf28-6b96-4c02-f532-843ddfca6348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: Here are the booking details for user123:\n",
            "\n",
            "- Name: Ravi\n",
            "- Email: ravi@gmail.com\n",
            "- Phone: 39429384923\n",
            "- Date: April 20th\n",
            "- Time: 12PM\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t0TSGGmfbIx"
      },
      "source": [
        "As you can see above the final booking details are sent to LLM for final response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS0wfl7IfQ6H"
      },
      "source": [
        "### Experiment-2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_1LAz5AfT5F"
      },
      "source": [
        "#### Create Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7TpumMcZK4X"
      },
      "outputs": [],
      "source": [
        "get_booking_state_tool = FunctionTool.from_defaults(fn=get_booking_state,\n",
        "                                                 return_direct=True)\n",
        "update_booking_tool = FunctionTool.from_defaults(fn=update_booking)\n",
        "create_booking_tool = FunctionTool.from_defaults(fn=create_booking,\n",
        "                                                 return_direct=True)\n",
        "confirm_booking_tool = FunctionTool.from_defaults(fn=confirm_booking,\n",
        "                                                  return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCzV3KbtZNWM"
      },
      "outputs": [],
      "source": [
        "user = \"user123\"\n",
        "prefix_messages = [\n",
        "    ChatMessage(\n",
        "        role=\"system\",\n",
        "        content=(\n",
        "            f\"You are now connected to the booking system and helping {user} with making a booking. \"\n",
        "            \"Only enter details that the user has explicitly provided. \"\n",
        "            \"Do not make up any details.\"\n",
        "        ),\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XAC_VSfWHg"
      },
      "source": [
        "#### Create Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjiWREXpZPJU"
      },
      "outputs": [],
      "source": [
        "worker = FunctionCallingAgentWorker(\n",
        "    tools=[\n",
        "        get_booking_state_tool,\n",
        "        update_booking_tool,\n",
        "        create_booking_tool,\n",
        "        confirm_booking_tool,\n",
        "    ],\n",
        "    llm=llm,\n",
        "    prefix_messages=prefix_messages,\n",
        "    max_function_calls=10,\n",
        "    allow_parallel_tool_calls=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "agent = AgentRunner(worker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSzTO6vMfYUE"
      },
      "source": [
        "#### Let's create Booking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arc2o-H1ZQ8D",
        "outputId": "c7232407-a0fb-4350-f2b2-7c5ba47d51b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Hello! I would like to make a booking.\n",
            "=== Calling Function ===\n",
            "Calling function: create_booking with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "Booking created, but not yet confirmed. Please provide your name, email, phone, date, and time.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Hello! I would like to make a booking.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbdh9i7AZTck",
        "outputId": "d6fbef68-1ff6-4493-b3f9-7ceaa45f5c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Sure! My name is Ravi, and my email is ravi@gmail.com\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"name\", \"value\": \"Ravi\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with name = Ravi\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"email\", \"value\": \"ravi@gmail.com\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with email = ravi@gmail.com\n",
            "=== LLM Response ===\n",
            "Thank you, Ravi. Could you please provide your phone number, and the date and time you would like to make the booking for?\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Sure! My name is Ravi, and my email is ravi@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ta0JFyUZdQd",
        "outputId": "2a3f229a-2790-42e4-823b-71d8af518f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Cool. Phone number is 39429384923, preferred data and time are April 20th and 12PM respectively.\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"phone\", \"value\": \"39429384923\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with phone = 39429384923\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"date\", \"value\": \"April 20th\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with date = April 20th\n",
            "=== Calling Function ===\n",
            "Calling function: update_booking with args: {\"user_id\": \"user123\", \"property\": \"time\", \"value\": \"12PM\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 updated with time = 12PM\n",
            "=== Calling Function ===\n",
            "Calling function: confirm_booking with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "Booking ID user123 confirmed!\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Cool. Phone number is 39429384923, preferred data and time are April 20th and 12PM respectively.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek46fXZnZe0l",
        "outputId": "eed56eb2-cf6d-4768-f69f-f061177a19c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: provide the booking details\n",
            "=== Calling Function ===\n",
            "Calling function: get_booking_state with args: {\"user_id\": \"user123\"}\n",
            "=== Function Output ===\n",
            "{'name': 'Ravi', 'email': 'ravi@gmail.com', 'phone': '39429384923', 'date': 'April 20th', 'time': '12PM'}\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"provide the booking details\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExLsCvJ0Ziy2",
        "outputId": "c530816e-caac-43a1-f0bd-7778f5bf3350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'Ravi', 'email': 'ravi@gmail.com', 'phone': '39429384923', 'date': 'April 20th', 'time': '12PM'}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHe6p99qfiYO"
      },
      "source": [
        "As you can see the above response with `return_dict` enabled is directly from tool and not sent to LLM for final response"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
